# ============================================================================
# AI-Native MVP - Environment Variables (Fase 8 - Development)
# ============================================================================
# This is a working .env for development
# DO NOT commit to version control in production
# ============================================================================

# Database Configuration
DATABASE_URL=postgresql+asyncpg://postgres:postgres@127.0.0.1:5433/ai_native

# Redis Configuration
REDIS_URL=redis://localhost:6379/0

# FastAPI Configuration
APP_NAME=AI-Native MVP V3
APP_VERSION=3.0.0
DEBUG=True
SECRET_KEY=fase8-dev-secret-key-change-in-production-please
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:5173,http://localhost:8001

# LLM Configuration (OpenAI) - Optional for Analytics
OPENAI_API_KEY=
OPENAI_MODEL=gpt-4o-mini

# LLM Configuration (Anthropic) - Optional
ANTHROPIC_API_KEY=
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

# LLM Configuration (Ollama) - Optional
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2:latest

# LLM Configuration (Mistral AI) - ACTIVE
# Get API key from: https://console.mistral.ai/
MISTRAL_API_KEY=dIP8GSbBnLhyGCSOiHvZn96W7CLgYM2J
# Mistral Model (default: mistral-small-latest)
# Small: Rápido y económico para la mayoría de operaciones
# Large: Análisis profundo automático cuando es necesario
MISTRAL_MODEL=mistral-small-latest
# Temperature (0.0 = determinista, 1.0 = creativo)
MISTRAL_TEMPERATURE=0.7
# Max tokens per response
MISTRAL_MAX_TOKENS=2048
# Request timeout in seconds
MISTRAL_TIMEOUT=60
# Max retries on failure
MISTRAL_MAX_RETRIES=3

# LangSmith (Optional - Observability)
LANGCHAIN_TRACING_V2=false
LANGCHAIN_API_KEY=
LANGCHAIN_PROJECT=ai-native-mvp-v3

# Authentication
JWT_SECRET_KEY=fase8-jwt-secret-key-development-only
JWT_ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=60

# Logging
LOG_LEVEL=INFO
