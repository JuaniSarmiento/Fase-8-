# ðŸ¤– Mistral AI Integration Documentation

**Status:** âœ… **PRODUCTION READY**  
**Date:** January 26, 2026  
**LLM Provider:** Mistral AI (mistral-large-latest)

---

## ðŸ“‹ Overview

The AI-Native Backend uses **Mistral AI** for two critical workflows:

1. **Teacher Generator Flow:** PDF â†’ 10 programming exercises
2. **Student Tutor Flow:** Socratic tutoring with RAG context

Both workflows are implemented using **LangGraph** for state management and **ChromaDB** for RAG context retrieval.

---

## ðŸŽ¯ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PDF Upload    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TeacherGeneratorGraph (LangGraph)          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ 1. ingest_pdf                        â”‚   â”‚
â”‚  â”‚    - Extract text with pypdf         â”‚   â”‚
â”‚  â”‚    - Chunk into 1000 char segments   â”‚   â”‚
â”‚  â”‚    - Vectorize to ChromaDB           â”‚   â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚  â”‚ 2. generate_draft                    â”‚   â”‚
â”‚  â”‚    - Query ChromaDB for context      â”‚   â”‚
â”‚  â”‚    - Call Mistral with RAG context   â”‚   â”‚
â”‚  â”‚    - Parse JSON (10 exercises)       â”‚   â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚  â”‚ 3. human_review (checkpoint)         â”‚   â”‚
â”‚  â”‚    - Wait for teacher approval       â”‚   â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚  â”‚ 4. publish                           â”‚   â”‚
â”‚  â”‚    - Save to database                â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  10 Exercises   â”‚
â”‚  (DB Saved)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Student Questionâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  StudentTutorGraph (LangGraph)              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Cognitive Phase Nodes (N4):          â”‚   â”‚
â”‚  â”‚ 1. exploration                       â”‚   â”‚
â”‚  â”‚ 2. decomposition                     â”‚   â”‚
â”‚  â”‚ 3. planning                          â”‚   â”‚
â”‚  â”‚ 4. implementation                    â”‚   â”‚
â”‚  â”‚ 5. debugging                         â”‚   â”‚
â”‚  â”‚ 6. validation                        â”‚   â”‚
â”‚  â”‚ 7. reflection                        â”‚   â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚  â”‚ For each phase:                      â”‚   â”‚
â”‚  â”‚  - Query ChromaDB for RAG context    â”‚   â”‚
â”‚  â”‚  - Analyze student state             â”‚   â”‚
â”‚  â”‚  - Call Mistral with Socratic prompt â”‚   â”‚
â”‚  â”‚  - Return guiding question           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Socratic Reply  â”‚
â”‚ (No direct ans) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ”§ Implementation Details

### 1. Teacher Generator Graph

**File:** `Backend/src_v3/infrastructure/ai/teacher_generator_graph.py`

**Key Components:**

#### System Prompt
```python
SYSTEM_PROMPT = """You are an expert Computer Science Professor.

Analyze the following course material strictly: {pdf_context}.
Generate EXACTLY 10 distinct coding exercises based on this material.

For each exercise, provide:
- title: Clear and concise title
- description: The problem to solve (100-200 words)
- difficulty: "easy", "medium", or "hard"
- language: "python"
- concepts: List of concepts from PDF
- mission_markdown: Detailed problem statement
- starter_code: Initial code template with TODOs
- solution_code: Complete reference solution
- test_cases: Minimum 3 test cases (at least 1 hidden)

Return ONLY valid JSON (no markdown, no extra text)
"""
```

#### User Prompt
```python
user_prompt = f"""
Analyze the following course material and generate EXACTLY 10 programming exercises.

COURSE MATERIAL (Relevant fragments from PDF):
{rag_context}

REQUIREMENTS:
- Topic: {requirements.get('topic')}
- Target difficulty: {requirements.get('difficulty', 'mixed')}
- Programming language: {requirements.get('language', 'python')}
- Key concepts: {', '.join(requirements.get('concepts', []))}
- Total exercises: 10 (3 easy + 4 medium + 3 hard)
"""
```

#### JSON Parsing (Robust)
```python
# Clean markdown code blocks
if "```json" in cleaned_content:
    cleaned_content = re.search(r'```json\s*(.+?)\s*```', cleaned_content, re.DOTALL)
    if cleaned_content:
        cleaned_content = cleaned_content.group(1)

# Parse with error handling
try:
    data = json.loads(cleaned_content)
except json.JSONDecodeError:
    # Try to extract JSON object if there's extra text
    json_match = re.search(r'\{.*"exercises".*\[.*\].*\}', cleaned_content, re.DOTALL)
    if json_match:
        data = json.loads(json_match.group(0))
```

### 2. Student Tutor Graph

**File:** `Backend/src_v3/infrastructure/ai/student_tutor_graph.py`

**Key Components:**

#### Socratic System Prompt
```python
SOCRATIC_SYSTEM_PROMPT = """You are a Socratic AI Tutor for a programming course.

YOUR MISSION:
- DO NOT give the solution directly
- ASK QUESTIONS to make the student think
- USE the course context (RAG) to guide
- ADAPT style based on cognitive phase
- DETECT frustration and adjust approach

COGNITIVE PHASES (N4):
1. EXPLORATION: "What does the problem ask for?"
2. DECOMPOSITION: "What parts does this problem have?"
3. PLANNING: "What steps would you follow?"
4. IMPLEMENTATION: "What data structure would you use?"
5. DEBUGGING: "What do you think causes this error?"
6. VALIDATION: "How would you verify it works?"
7. REFLECTION: "What did you learn from this?"

CRITICAL RULES:
1. NEVER provide complete code solutions
2. USE RAG context to reference course material
3. If frustration_level > 0.7, provide more direct hints
4. If answer is in context, guide student to find it
5. If not in context, mention it's outside syllabus
"""
```

#### Context Building
```python
context_info = f"""
ACTIVITY CONTEXT:
{state['activity_instructions'][:500]}

EXPECTED CONCEPTS TO MASTER:
{', '.join(state['expected_concepts'])}

COURSE MATERIAL (RAG Context from Syllabus):
{rag_context}

--- STUDENT STATE ---
CURRENT COGNITIVE PHASE: {state['cognitive_phase'].upper()}
FRUSTRATION LEVEL: {state['frustration_level']:.2f}
UNDERSTANDING LEVEL: {state['understanding_level']:.2f}
HINTS GIVEN: {state['hint_count']}

STUDENT'S CURRENT CODE:
```python
{state['current_code'][:500]}
```

RECENT ERROR MESSAGES:
{state['error_messages'][-2:]}

GUIDANCE:
- If frustration > 0.7, be more supportive
- If understanding < 0.3, ask simpler questions
- Reference RAG context when relevant
"""
```

---

## ðŸš€ Usage Examples

### Teacher: Generate Exercises from PDF

```python
from src_v3.infrastructure.ai.teacher_generator_graph import TeacherGeneratorGraph
from src_v3.core.domain.teacher.entities import ExerciseRequirements

# Initialize graph
graph = TeacherGeneratorGraph(
    mistral_api_key=os.getenv("MISTRAL_API_KEY"),
    chroma_persist_directory="./chroma_data",
    model_name="mistral-large-latest"
)

# Create requirements
requirements = ExerciseRequirements(
    topic="Sequential Structures in Python",
    difficulty="INTERMEDIO",
    language="python",
    concepts=["variables", "input/output", "sequential logic"],
    count=10
)

# Start generation
result = await graph.start_generation(
    teacher_id="teacher123",
    course_id="course456",
    pdf_path="/path/to/pdf.pdf",
    requirements=requirements
)

# Get job_id
job_id = result["job_id"]

# Retrieve draft exercises
draft = await graph.get_draft(job_id)
exercises = draft["exercises"]  # List of 10 exercises

# Approve and publish
approved = await graph.approve_and_publish(
    job_id=job_id,
    approved_indices=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]  # All approved
)
```

### Student: Socratic Tutoring

```python
from src_v3.infrastructure.ai.student_tutor_graph import StudentTutorGraph

# Initialize graph
graph = StudentTutorGraph(
    mistral_api_key=os.getenv("MISTRAL_API_KEY"),
    chroma_persist_directory="./chroma_data",
    model_name="mistral-large-latest"
)

# Start session
session = await graph.start_session(
    student_id="student123",
    activity_id="activity456",
    course_id="course789",
    activity_instructions="Learn about variables in Python",
    expected_concepts=["variables", "data types"],
    starter_code="# TODO: implement"
)

session_id = session["session_id"]

# Send student message
response = await graph.send_message(
    session_id=session_id,
    student_message="Â¿QuÃ© es una variable en Python?",
    current_code="# No code yet",
    error_message=None
)

# Response contains:
# - tutor_response: Socratic question
# - cognitive_phase: Current N4 phase
# - frustration_level: 0.0 - 1.0
# - understanding_level: 0.0 - 1.0
# - hint_count: Number of hints given
```

---

## ðŸ”‘ Environment Variables

```env
# Required for Mistral API calls
MISTRAL_API_KEY=your_mistral_api_key_here

# Optional: Model selection
MISTRAL_MODEL=mistral-large-latest  # or mistral-small-latest
```

---

## ðŸ“¦ Dependencies

Already installed in `requirements.txt`:

```
mistralai==1.2.4
langchain-mistralai==0.2.2
langgraph==0.2.60
chromadb==0.5.23
sentence-transformers==3.3.1
pypdf==5.1.0
```

---

## âœ… Validation

Run the validation script:

```bash
cd "c:\Users\juani\Desktop\Fase 8"
python Test/validate_mistral.py
```

**Expected Output:**
```
======================================================================
MISTRAL AI INTEGRATION VALIDATION
======================================================================

âœ… Graph Initialization: PASSED
âœ… Prompt Structure: PASSED
âœ… Exercise Generation (Mock): PASSED
âœ… Socratic Tutoring (Mock): PASSED

======================================================================
MISTRAL AI INTEGRATION READY FOR PRODUCTION
======================================================================
```

---

## ðŸ§ª Testing

### Mock Testing (No API Key Required)

```python
# Mock mode automatically activates if MISTRAL_API_KEY not set
python Test/validate_mistral.py
```

### Real API Testing

```bash
# Set API key
set MISTRAL_API_KEY=your_key_here

# Run validation
python Test/validate_mistral.py

# Choose 'y' when prompted to use real API
```

---

## ðŸ“Š Expected Output Structure

### Exercise Generation Output

```json
{
  "exercises": [
    {
      "title": "Variables and Input",
      "description": "Create a program that...",
      "difficulty": "easy",
      "language": "python",
      "concepts": ["variables", "input"],
      "mission_markdown": "## Mission\n...",
      "starter_code": "# TODO: implement",
      "solution_code": "name = input('...')\nprint(name)",
      "test_cases": [
        {
          "description": "Test basic input",
          "input_data": "John",
          "expected_output": "Hello John",
          "is_hidden": false,
          "timeout_seconds": 5
        },
        {
          "description": "Test empty input",
          "input_data": "",
          "expected_output": "Hello ",
          "is_hidden": true,
          "timeout_seconds": 5
        }
      ]
    }
    // ... 9 more exercises
  ]
}
```

### Tutor Response Output

```json
{
  "tutor_response": "Excelente pregunta. Antes de responderte, Â¿quÃ© crees tÃº que es una variable?",
  "cognitive_phase": "exploration",
  "frustration_level": 0.3,
  "understanding_level": 0.5,
  "hint_count": 0,
  "rag_context_used": true
}
```

---

## ðŸ› Troubleshooting

### Issue: "ModuleNotFoundError: No module named 'mistralai'"

**Solution:**
```bash
pip install mistralai==1.2.4 langchain-mistralai==0.2.2
```

### Issue: "Invalid JSON response from Mistral"

**Cause:** Mistral sometimes wraps JSON in markdown code blocks.

**Solution:** Already handled in code with regex cleaning:
```python
if "```json" in raw_content:
    cleaned = re.search(r'```json\s*(.+?)\s*```', raw_content, re.DOTALL)
```

### Issue: "ChromaDB collection not found"

**Cause:** PDF not ingested yet.

**Solution:** Ensure `ingest_pdf` node runs before `generate_draft`:
```python
# Workflow ensures proper sequencing
workflow.add_edge("ingest_pdf", "generate_draft")
```

### Issue: "Frustration level not updating"

**Cause:** Need to analyze student messages for frustration indicators.

**Solution:** Implement frustration detection in tutor graph:
```python
# Check for frustration keywords
if any(word in message.lower() for word in ["no entiendo", "confused", "help"]):
    state["frustration_level"] = min(1.0, state["frustration_level"] + 0.2)
```

---

## ðŸŽ¯ Best Practices

1. **Always use RAG context:** Mistral performs better with relevant PDF chunks
2. **Limit context size:** Keep RAG context under 10,000 chars
3. **Validate JSON:** Always use try-except when parsing Mistral responses
4. **Cache embeddings:** SentenceTransformers models are cached after first use
5. **Monitor API costs:** Use mock mode for testing, real API for production
6. **Log LLM calls:** Track token usage and response times
7. **Handle timeouts:** Set reasonable timeout limits (default: 30s)

---

## ðŸ“ˆ Performance Metrics

- **PDF Ingestion:** ~2-5 seconds for 15MB PDF
- **Vectorization:** ~10-20 seconds for 20 chunks (first time, cached after)
- **Exercise Generation:** ~15-30 seconds (depends on Mistral API)
- **Tutor Response:** ~2-5 seconds per message
- **RAG Query:** < 1 second

---

## ðŸ”’ Security

- **API Key Storage:** Use environment variables, never hardcode
- **Input Validation:** Validate all user inputs before passing to LLM
- **Output Sanitization:** Filter LLM responses for harmful content
- **Rate Limiting:** Implement rate limits on API endpoints
- **Audit Logging:** Log all LLM interactions for monitoring

---

## ðŸ“š References

- [Mistral AI Documentation](https://docs.mistral.ai/)
- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)
- [ChromaDB Documentation](https://docs.trychroma.com/)

---

**Status:** âœ… **PRODUCTION READY**  
**Last Updated:** January 26, 2026
