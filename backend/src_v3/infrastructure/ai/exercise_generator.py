"""Exercise Generator Agent for Fase 8.

Uses the generic LLMProviderFactory (Mistral/Ollama/etc.) plus optional
RAG context from Chroma to generate a `GeneratedExercise` domain entity.

The agent is intentionally conservative: it asks the LLM for a small JSON
structure and validates it. If anything fails, callers should fall back to
safe deterministic generation.
"""

from __future__ import annotations

import json
from typing import Optional

from backend.src_v3.infrastructure.llm.factory import LLMProviderFactory
from backend.src_v3.infrastructure.llm.base import LLMMessage, LLMRole
from backend.src_v3.core.domain.teacher.entities import (
    ExerciseRequirements,
    GeneratedExercise,
    TestCase,
)


SYSTEM_PROMPT = """Eres un profesor experto en programaci√≥n Python. Tu tarea es crear ejercicios de programaci√≥n de alta calidad pedag√≥gica.

## FORMATO DE RESPUESTA (JSON ESTRICTO):
Responde √öNICAMENTE con un JSON v√°lido, sin texto adicional:

{
  "title": "T√≠tulo descriptivo del ejercicio",
  "description": "Descripci√≥n breve en 1-2 l√≠neas",
  "mission_markdown": "CONSIGNA DETALLADA (ver estructura abajo)",
  "starter_code": "SOLO COMENTARIOS GU√çA",
  "solution_code": "C√ìDIGO COMPLETO FUNCIONAL",
  "test_cases": [...]
}

## ESTRUCTURA OBLIGATORIA DE mission_markdown:

El campo mission_markdown DEBE tener esta estructura EXACTA en markdown:

```
## üéØ Objetivo

[Descripci√≥n clara de qu√© debe lograr el estudiante - 2-3 oraciones]

## üìã Requisitos

1. [Requisito espec√≠fico 1]
2. [Requisito espec√≠fico 2]
3. [Requisito espec√≠fico 3]

## ‚ö†Ô∏è Restricciones

- [Qu√© NO debe hacer el estudiante, si aplica]
- [Por ejemplo: "No uses funciones built-in como sum()"]

## üí° Ejemplo

**Entrada:**
```python
# Ejemplo de datos de entrada
```

**Salida esperada:**
```
# Salida que debe producir el c√≥digo
```

## üîç Pistas

- [Pista 1 sin revelar la soluci√≥n]
- [Pista 2 guiando el razonamiento]
```

## REGLAS PARA starter_code (MUY IMPORTANTE):

El starter_code debe contener √öNICAMENTE comentarios que gu√≠en al estudiante.
‚ùå NO incluyas c√≥digo funcional
‚ùå NO incluyas variables definidas
‚ùå NO incluyas funciones parcialmente implementadas
‚úÖ SOLO comentarios explicativos

EJEMPLO CORRECTO de starter_code:
```python
# Ejercicio: [Nombre del ejercicio]
#
# Tu tarea:
# 1. Define una funci√≥n llamada [nombre]
# 2. La funci√≥n debe recibir [par√°metros]
# 3. Debe retornar [descripci√≥n del resultado]
#
# Escribe tu c√≥digo aqu√≠:

```

EJEMPLO INCORRECTO (NO HACER):
```python
def mi_funcion(x):
    # TODO: completar
    pass
```

## REGLAS PARA solution_code:

El solution_code debe ser:
- C√≥digo Python 100% funcional y ejecutable
- Bien comentado explicando la l√≥gica
- Incluye la funci√≥n/c√≥digo principal
- Incluye llamada de prueba con print() para verificar
- Ser√° usado como REFERENCIA para evaluar al estudiante

EJEMPLO de solution_code:
```python
def calcular_factorial(n):
    \"\"\"Calcula el factorial de un n√∫mero.\"\"\"
    if n == 0 or n == 1:
        return 1
    resultado = 1
    for i in range(2, n + 1):
        resultado *= i
    return resultado

# Prueba
print(f"Factorial de 5: {calcular_factorial(5)}")  # Output: 120
```

## REGLAS PARA test_cases:

- M√≠nimo 2 test cases, m√°ximo 5
- Cada test case debe tener input y output claros
- No uses input(), open(), eval(), exec()
- Los tests deben ser ejecutables autom√°ticamente
"""


class ExerciseGeneratorAgent:
    """Small wrapper around the generic LLM provider to generate exercises."""

    def __init__(self) -> None:
        # Use provider from env (typically mistral in docker-compose)
        self.llm = LLMProviderFactory.create_from_env()

    async def generate(
        self,
        requirements: ExerciseRequirements,
        rag_context: Optional[str] = None,
    ) -> GeneratedExercise:
        """Generate a single exercise using LLM + optional RAG context.

        May raise exceptions if LLM is not configured or output is invalid.
        Callers should catch and provide a fallback if needed.
        """
        topic = requirements.topic
        difficulty = requirements.difficulty
        language = requirements.language
        concepts = ", ".join(requirements.concepts or [])

        user_prompt = f"""
Genera un ejercicio de programaci√≥n.

TEMA: {topic}
DIFICULTAD: {difficulty}
LENGUAJE: {language}
CONCEPTOS: {concepts or 'generales'}

CONTEXTO DEL CURSO (RAG):
{rag_context or 'N/A'}

Recuerda responder SOLO con el JSON pedido.
"""

        messages = [
            LLMMessage(role=LLMRole.SYSTEM, content=SYSTEM_PROMPT),
            LLMMessage(role=LLMRole.USER, content=user_prompt),
        ]

        response = await self.llm.generate(messages, temperature=0.5, max_tokens=1200)
        raw = response.content.strip()

        # Intentar limpiar bloques ```json
        if raw.startswith("```json"):
            raw = raw[7:]
        if raw.startswith("```"):
            raw = raw[3:]
        if raw.endswith("```"):
            raw = raw[:-3]

        data = json.loads(raw)

        title = data.get("title") or f"Ejercicio: {topic}"
        description = data.get("description") or f"Ejercicio sobre {topic}"
        mission_markdown = data.get("mission_markdown") or f"## Misi√≥n\n\nResuelve un ejercicio sobre {topic}."
        starter_code = data.get("starter_code") or "# TODO: implementa la soluci√≥n aqu√≠\n"
        solution_code = data.get("solution_code") or "# Soluci√≥n de referencia\n"

        raw_tests = data.get("test_cases") or []
        test_cases: list[TestCase] = []
        for idx, tc in enumerate(raw_tests, start=1):
            test_cases.append(
                TestCase(
                    test_number=idx,
                    description=tc.get("description") or f"Test {idx}",
                    input_data=tc.get("input_data") or "",
                    expected_output=tc.get("expected_output") or "",
                    is_hidden=bool(tc.get("is_hidden", False)),
                    timeout_seconds=int(tc.get("timeout_seconds") or 5),
                )
            )

        # Asegurar al menos 2 tests para respetar invariantes de dominio
        if len(test_cases) < 2:
            test_cases.append(
                TestCase(
                    test_number=len(test_cases) + 1,
                    description="Test adicional auto-generado",
                    input_data="",
                    expected_output="",
                    is_hidden=True,
                    timeout_seconds=5,
                )
            )

        exercise = GeneratedExercise(
            exercise_id="",  # Se asigna en el caso de uso
            title=title,
            description=description,
            difficulty=difficulty,
            language=language,
            mission_markdown=mission_markdown,
            starter_code=starter_code,
            solution_code=solution_code,
            test_cases=test_cases,
            concepts=requirements.concepts or [],
            learning_objectives=[f"Comprender {topic}"],
            estimated_time_minutes=requirements.estimated_time_minutes,
            rag_sources=[],
        )

        return exercise
